{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using Siphon to Download METAR Data\n",
    "\n",
    "In this series, we work on some simpler tasks:\n",
    "1. Making a line plot using matplotlib\n",
    "2. **Downloading a time-series of data from a THREDDS server**\n",
    "3. Plotting the data using matplotlib"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Finding the METAR Data\n",
    "\n",
    "METAR are a standard form of surface observation, where data are coded into a text format. Luckily for us, there are already decoded METAR observations available to us on [Unidata's THREDDS server](http://thredds.ucar.edu/thredds/). If we surf there, we see \n",
    "\"Observation Data\", which sound like what we're looking for; from there, we can click on \"Metar Station Data\". This page offers \"files\", which are individual netCDF files containing the data, or the \"Feature Collection\", which aggregates these files together. We want this latter link, which allows us to access the entire collection of data; this permits accessing multiple files as one logical dataset.\n",
    "\n",
    "We'll be using Unidata's Python library for talking to THREDDS, [Siphon](http://siphon.readthedocs.org), to access this information in a way that makes it easy to program. So we start by importing the `TDSCatalog` class from `siphon` and giving it the URL to the page (catalog) to which we just navigated.\n",
    "\n",
    "**Note:** Instead of giving it the link to the HTML catalog, we change the extension to XML, which asks the TDS for the XML version of the catalog. This is much better to work with in code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from siphon.catalog import TDSCatalog\n",
    "\n",
    "catalog = TDSCatalog('http://thredds.ucar.edu/thredds/catalog/nws/metar/ncdecoded/catalog.xml?'\n",
    "                     'dataset=nws/metar/ncdecoded/Metar_Station_Data_fc.cdmr')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From this `catalog` we want to get to the METAR dataset. We can see the datasets in the catalog by looking at the `datasets` attribute on `catalog`. This is a Python dictionary, mapping the name of the dataset to a Python `Dataset` object (which came from more XML supplied by the TDS â€” notice a theme?) Since this is a dictionary, we can look at a list of the keys:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Feature Collection']"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(catalog.datasets)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As expected, there's only a single dataset, the Feature Collection we're interested in. We can grab the `Dataset` instance for the feature collection and store in `fc` with:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "fc = list(catalog.datasets.values())[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Downloading the Data\n",
    "\n",
    "To download the data, we first look at what access methods are available for this dataset; to do this, we look at the `access_urls` attribute of `fc`, which is a Python dictionary mapping the type of access to the corresponding URL:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['NetcdfSubset']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(fc.access_urls)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This means the feature collection is only accessible using the [netCDF Subset Service (NCSS)](https://www.unidata.ucar.edu/software/thredds/current/tds/reference/NetcdfSubsetServiceReference.html). NCSS is a TDS web-service that allows downloading subsets of datasets using lat/lon or projection points (or bounding boxes) and date ranges. It's similar to OPenDAP except that you don't need to figure out what indices of data you need. You can access this service using an [HTML form](http://thredds.ucar.edu/thredds/ncss/nws/metar/ncdecoded/Metar_Station_Data_fc.cdmr/dataset.html) for the dataset. This requires human input; what we want is programmatic access.\n",
    "\n",
    "Fortunately, Siphon provides code to make accessing NCSS painless. The first step is to import the `NCSS` class from siphon and point it to the NCSS access URL on the feature collection."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from siphon.ncss import NCSS\n",
    "ncss = NCSS(fc.access_urls['NetcdfSubset'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This handles setting up access to that NCSS URL, as well as downloading and parsing various pieces of XML metadata. For instance, if we want to see what variables are available in this dataset, we can look at the `variables` attribute on `ncss`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'air_pressure_at_sea_level',\n",
       " 'air_temperature',\n",
       " 'cloud_area_fraction',\n",
       " 'dew_point_temperature',\n",
       " 'hectoPascal_ALTIM',\n",
       " 'high_cloud_area_fraction',\n",
       " 'high_cloud_base_altitude',\n",
       " 'inches_ALTIM',\n",
       " 'low_cloud_area_fraction',\n",
       " 'low_cloud_base_altitude',\n",
       " 'middle_cloud_area_fraction',\n",
       " 'middle_cloud_base_altitude',\n",
       " 'numChildren',\n",
       " 'precipitation_amount_24',\n",
       " 'precipitation_amount_hourly',\n",
       " 'report',\n",
       " 'report_id',\n",
       " 'report_length',\n",
       " 'snowfall_amount',\n",
       " 'snowfall_amount_last_hour',\n",
       " 'visibility_in_air',\n",
       " 'visibility_in_air_direction',\n",
       " 'visibility_in_air_surface',\n",
       " 'visibility_in_air_vertical',\n",
       " 'weather',\n",
       " 'wind_from_direction',\n",
       " 'wind_from_direction_max',\n",
       " 'wind_from_direction_min',\n",
       " 'wind_gust',\n",
       " 'wind_peak_from_direction',\n",
       " 'wind_peak_speed',\n",
       " 'wind_peak_time',\n",
       " 'wind_speed',\n",
       " 'xfields'}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ncss.variables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So now let's make a request for data. For this case we'll get the latest observation for my location, asking for the air_temperature, wind direction, and wind speed. The first step is to ask the NCSS client to make a new query for us. This `query` object is used to assemble all of the parameters we'll be sending to the server in order to make our request."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "query = ncss.query()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first step is to set the query to ask for data for the station closest to our lon/lat point (mine is -105W, 40N):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "var=air_temperature&var=wind_from_direction&var=wind_speed&time=2016-05-17T22%3A22%3A02.800345&latitude=39.9&longitude=-104.6&accept=netcdf4"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query.lonlat_point(-104.6, 39.9)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice that we can also see the string representation of the query, which is shown as the standard URL string used to make the request to the web server. The next step is to state what time we want. We'll use Python's `datetime` standard library module to easily get the current time:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "var=air_temperature&var=wind_from_direction&var=wind_speed&time=2016-05-17T22%3A22%3A26.788581&latitude=39.9&longitude=-104.6&accept=netcdf4"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from datetime import datetime\n",
    "query.time(datetime.utcnow())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we add the variables for which we'd like data, using the names listed above:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "var=air_temperature&var=wind_speed&var=wind_from_direction&time=2016-05-17T22%3A22%3A26.788581&latitude=39.9&longitude=-104.6&accept=netcdf4"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query.variables('air_temperature', 'wind_from_direction', 'wind_speed')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lastly, we ask the TDS to return data in netCDF4 format:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "var=air_temperature&var=wind_speed&var=wind_from_direction&time=2016-05-17T22%3A22%3A26.788581&latitude=39.9&longitude=-104.6&accept=netcdf4"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query.accept('netcdf4')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also check that we haven't mis-typed any variable names by using the `validate_query` method on the NCSS client, which checks (as much as it can) whether what we're asking for makes sense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ncss.validate_query(query)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All that's left now is to get the data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data = ncss.get_data(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<class 'netCDF4._netCDF4.Dataset'>\n",
       "root group (NETCDF4_CLASSIC data model, file format HDF5):\n",
       "    Conventions: CF-1.6\n",
       "    history: Written by CFPointWriter\n",
       "    title: Extracted data from TDS Feature Collection Metar Station Data\n",
       "    featureType: timeSeries\n",
       "    time_coverage_start: 2016-05-17T21:53:00Z\n",
       "    time_coverage_end: 2016-05-17T21:53:00Z\n",
       "    geospatial_lat_min: 39.8694989319\n",
       "    geospatial_lat_max: 39.8704989319\n",
       "    geospatial_lon_min: -104.670498169\n",
       "    geospatial_lon_max: -104.669498169\n",
       "    dimensions(sizes): obs(1), station(1), station_description_strlen(24), wmo_id_strlen(5), station_id_strlen(3)\n",
       "    variables(dimensions): float64 \u001b[4mlatitude\u001b[0m(station), float64 \u001b[4mlongitude\u001b[0m(station), float64 \u001b[4mstationAltitude\u001b[0m(station), |S1 \u001b[4mstation_id\u001b[0m(station,station_id_strlen), |S1 \u001b[4mstation_description\u001b[0m(station,station_description_strlen), |S1 \u001b[4mwmo_id\u001b[0m(station,wmo_id_strlen), float64 \u001b[4mtime\u001b[0m(obs), int32 \u001b[4mstationIndex\u001b[0m(obs), int32 \u001b[4mwind_from_direction\u001b[0m(obs), float32 \u001b[4mwind_speed\u001b[0m(obs), float32 \u001b[4mair_temperature\u001b[0m(obs)\n",
       "    groups: "
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Working With the Data\n",
    "\n",
    "Siphon takes care of opening the binary blob of data that comes from the server, using the excellent [netcdf4-python](https://unidata.github.io/netcdf4-python/) library. This gives us an easy way to see what variables are present in the data returned:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['latitude',\n",
       " 'longitude',\n",
       " 'stationAltitude',\n",
       " 'station_id',\n",
       " 'station_description',\n",
       " 'wmo_id',\n",
       " 'time',\n",
       " 'stationIndex',\n",
       " 'wind_from_direction',\n",
       " 'wind_speed',\n",
       " 'air_temperature']"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(data.variables)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So we see in the data we got back not only the variable we asked for, but some useful metadata about the station the data came from. For instance, to get the station id we can do:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "b'DEN'"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "station_id = data['station_id'][:].tostring()\n",
    "station_id"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "or the description:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "b'DENVER INTNL ARPT, CO US'"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['station_description'][:].tostring()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "More importantly, let's see what the current conditions are:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8.0, 80, 2.057776)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['air_temperature'][0], data['wind_from_direction'][0], data['wind_speed'][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To truly make sense of that, we should probably also look at the units:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('Celsius', 'degrees', 'm/s')"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['air_temperature'].units, data['wind_from_direction'].units, data['wind_speed'].units"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Other Queries\n",
    "What if we wanted to get a bunch of stations in area instead of a single station? We just need to tweak the `query` and give it a box instead:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "var=air_temperature&var=wind_speed&var=wind_from_direction&time=2016-05-17T22%3A22%3A26.788581&east=-104&west=-106&south=39&north=41&accept=netcdf4"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query.lonlat_box(west=-106, east=-104, south=39, north=41)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `query` object is smart enough to replace the previous spatial query (for a single point) but keeps the rest of what we've asked for. We can now pass this to the NCSS client and get back much more data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data = ncss.get_data(query)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can look at all of the air temperature observations in that area:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-4.        ,  0.        ,  8.19999981,  8.        ,  8.        ,\n",
       "        9.        ,  5.        ], dtype=float32)"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['air_temperature'][:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next time, we'll wrap up the series by creating a meteogram using MetPy, Siphon, and matplotlib all together. For more information on what was covered today, we suggest looking at:\n",
    "\n",
    "- Siphon's [documentation](http://siphon.readthedocs.io)\n",
    "- Unidata's THREDDS [server](http://thredds.ucar.edu/thredds/) has more datasets you can explore\n",
    "\n",
    "For more of Unidata's work in Python, see:\n",
    "- [Unidata Notebook Gallery](http://github.com/Unidata/blog-notebooks) ([View Here](http://nbviewer.jupyter.org/github/unidata/notebook-gallery/tree/master/blog-notebooks))\n",
    "- [Notebooks](http://github.com/Unidata/unidata-python-workshop) from Unidata's Annual Python Training Workshop\n",
    "\n",
    "Was this too much detail? Too slow? Just right? Do you have suggestions on other topics or examples we should cover? Do you have a notebook you would like us to show off? We'd love to have your feedback. You can send a message to the (python-users AT unidata.ucar.edu) mailing list or send a message to support-python AT unidata.ucar.edu. You can also leave a comment below, directly on the blog post."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.5",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  },
  "widgets": {
   "state": {},
   "version": "1.1.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
